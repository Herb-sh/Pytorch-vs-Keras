{"cells":[{"cell_type":"markdown","metadata":{"id":"WA3hGuWXwSyL"},"source":["<div>\n","      <img src=\"https://upload.wikimedia.org/wikipedia/de/5/5b/Hochschule-aalen.svg\" width=\"400px\" align=\"right\"/>\n","</div>\n","\n","\n","\n","## MLDL Projekt: \n","# Implementierung von Deep Learning-Modellen \n","##### Vergleich von keras (tensorflow) und pytorch\n","##### eigene Implementierung von Modellen\n","##### kritischer Vergleich, Schlussfolgerungen, etc.\n","## Vorhersage von Flugverspätungen in USA\n","---\n","Modul: Machine Learning & Deep Learning\\\n","**Eugen Jeroschkin, Patrick Kurz, Andreas Schulz, Herbi Shtini**\\\n","Submission: 14.10.2022 | SS2022 | Prof. Dr. Andreas Theissler\n","\n","---"]},{"cell_type":"markdown","source":["---\n","## Vorhersage von Flugverspätungen in USA\n","### Implementierung PyTorch\n","---"],"metadata":{"id":"qYt7Z_ARbV4R"}},{"cell_type":"markdown","metadata":{"id":"H8bYt-5YqbEi"},"source":["<h2>Inhaltsverzeichnis</h1>\n","<ol>\n","  <li>Das Model</li>\n","  <li>Train & Test Methoden</li>\n","  <li>Cross-Validation</li>\n","  <li>Parameter-Tuning</li>\n","  <li>Model Speichern</li>\n","</ul>\n"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8206,"status":"ok","timestamp":1666622431054,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"},"user_tz":-120},"id":"u8Y8Cl97JNYN","outputId":"64ec4848-d775-48ac-b102-7e444d60e41c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ray in /usr/local/lib/python3.7/dist-packages (2.0.1)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (22.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray) (4.1.1)\n","Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (6.0)\n","Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.8.0)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.1)\n","Requirement already satisfied: grpcio<=1.43.0,>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.43.0)\n","Requirement already satisfied: virtualenv in /usr/local/lib/python3.7/dist-packages (from ray) (20.16.5)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.4)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray) (1.2.0)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.32.0->ray) (1.15.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.13.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.10.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.9.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n","Requirement already satisfied: distlib<1,>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray) (0.3.6)\n","Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv->ray) (2.5.2)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (3.0.3)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.41)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.1)\n","Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n","Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (4.13.0)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n","Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (1.2.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna) (5.10.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna) (3.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna) (1.1.3.post0)\n","Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.2)\n","Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.4.1)\n","Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.2)\n","Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n","Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.11.0)\n","Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"]}],"source":["!pip install ray\n","!pip install optuna\n","\n","from functools import partial\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import random_split\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt \n","\n","from functools import partial\n","from sklearn.model_selection import KFold\n","\n","from ray import tune, air\n","from ray.tune import CLIReporter\n","from ray.tune.schedulers import ASHAScheduler\n","from ray.tune.search.optuna import OptunaSearch\n","from ray.air import session\n","from ray.air.checkpoint import Checkpoint\n","\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"mtFIgs10EcTE","executionInfo":{"status":"ok","timestamp":1666622441070,"user_tz":-120,"elapsed":10041,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}}},"outputs":[],"source":["if 'google.colab' in str(get_ipython()):\n","  IN_COLAB = True\n","else:\n","  IN_COLAB = False\n","\n","if IN_COLAB:\n","  # Authenticate and create the PyDrive client.\n","  !pip install -U -q PyDrive\n","  from pydrive.auth import GoogleAuth\n","  from pydrive.drive import GoogleDrive\n","  from google.colab import auth\n","  from oauth2client.client import GoogleCredentials\n","\n","  auth.authenticate_user()\n","  gauth = GoogleAuth()\n","  gauth.credentials = GoogleCredentials.get_application_default()\n","  drive = GoogleDrive(gauth)\n","\n","  downloaded = drive.CreateFile({'id': '1eyIVS-zsTzQCE-b48ZG2RxoLlqBGAkH_'}) \n","  downloaded.GetContentFile('2018-prepared-filtered-sample.csv') "]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"elapsed":2924,"status":"ok","timestamp":1666622443971,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"},"user_tz":-120},"id":"1SB4dNjrInru","outputId":"eff759f3-1282-45ff-9d19-4406bca1d12c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        CRS_DEP_TIME       DISTANCE  CRS_ELAPSED_TIME      ARR_DELAY  \\\n","count  800000.000000  800000.000000     800000.000000  800000.000000   \n","mean     1328.280338     802.422635        141.343901      12.739946   \n","std       490.949374     599.559660         73.495999      34.732988   \n","min         1.000000      31.000000          1.000000       0.000000   \n","25%       913.000000     363.000000         88.000000       0.000000   \n","50%      1320.000000     634.000000        122.000000       0.000000   \n","75%      1735.000000    1035.000000        171.000000       8.000000   \n","max      2359.000000    4983.000000        704.000000     300.000000   \n","\n","       FL_DATE_WEEKDAY_1  FL_DATE_WEEKDAY_2  FL_DATE_WEEKDAY_3  \\\n","count      800000.000000      800000.000000      800000.000000   \n","mean            0.150964           0.143095           0.143526   \n","std             0.358014           0.350170           0.350609   \n","min             0.000000           0.000000           0.000000   \n","25%             0.000000           0.000000           0.000000   \n","50%             0.000000           0.000000           0.000000   \n","75%             0.000000           0.000000           0.000000   \n","max             1.000000           1.000000           1.000000   \n","\n","       FL_DATE_WEEKDAY_4  FL_DATE_WEEKDAY_5  FL_DATE_WEEKDAY_6  ...  \\\n","count      800000.000000      800000.000000      800000.000000  ...   \n","mean            0.148524           0.149910           0.122398  ...   \n","std             0.355619           0.356983           0.327745  ...   \n","min             0.000000           0.000000           0.000000  ...   \n","25%             0.000000           0.000000           0.000000  ...   \n","50%             0.000000           0.000000           0.000000  ...   \n","75%             0.000000           0.000000           0.000000  ...   \n","max             1.000000           1.000000           1.000000  ...   \n","\n","       FL_DATE_MONTH_3  FL_DATE_MONTH_4  FL_DATE_MONTH_5  FL_DATE_MONTH_6  \\\n","count    800000.000000    800000.000000    800000.000000    800000.000000   \n","mean          0.084120         0.083326         0.085755         0.086549   \n","std           0.277568         0.276375         0.280002         0.281173   \n","min           0.000000         0.000000         0.000000         0.000000   \n","25%           0.000000         0.000000         0.000000         0.000000   \n","50%           0.000000         0.000000         0.000000         0.000000   \n","75%           0.000000         0.000000         0.000000         0.000000   \n","max           1.000000         1.000000         1.000000         1.000000   \n","\n","       FL_DATE_MONTH_7  FL_DATE_MONTH_8  FL_DATE_MONTH_9  FL_DATE_MONTH_10  \\\n","count    800000.000000    800000.000000    800000.000000     800000.000000   \n","mean          0.089074         0.088785         0.081445          0.086284   \n","std           0.284850         0.284433         0.273517          0.280783   \n","min           0.000000         0.000000         0.000000          0.000000   \n","25%           0.000000         0.000000         0.000000          0.000000   \n","50%           0.000000         0.000000         0.000000          0.000000   \n","75%           0.000000         0.000000         0.000000          0.000000   \n","max           1.000000         1.000000         1.000000          1.000000   \n","\n","       FL_DATE_MONTH_11  FL_DATE_MONTH_12  \n","count     800000.000000     800000.000000  \n","mean           0.081177          0.083450  \n","std            0.273108          0.276561  \n","min            0.000000          0.000000  \n","25%            0.000000          0.000000  \n","50%            0.000000          0.000000  \n","75%            0.000000          0.000000  \n","max            1.000000          1.000000  \n","\n","[8 rows x 23 columns]"],"text/html":["\n","  <div id=\"df-5bbccaa2-66aa-4d93-899e-e8d06333ceb4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CRS_DEP_TIME</th>\n","      <th>DISTANCE</th>\n","      <th>CRS_ELAPSED_TIME</th>\n","      <th>ARR_DELAY</th>\n","      <th>FL_DATE_WEEKDAY_1</th>\n","      <th>FL_DATE_WEEKDAY_2</th>\n","      <th>FL_DATE_WEEKDAY_3</th>\n","      <th>FL_DATE_WEEKDAY_4</th>\n","      <th>FL_DATE_WEEKDAY_5</th>\n","      <th>FL_DATE_WEEKDAY_6</th>\n","      <th>...</th>\n","      <th>FL_DATE_MONTH_3</th>\n","      <th>FL_DATE_MONTH_4</th>\n","      <th>FL_DATE_MONTH_5</th>\n","      <th>FL_DATE_MONTH_6</th>\n","      <th>FL_DATE_MONTH_7</th>\n","      <th>FL_DATE_MONTH_8</th>\n","      <th>FL_DATE_MONTH_9</th>\n","      <th>FL_DATE_MONTH_10</th>\n","      <th>FL_DATE_MONTH_11</th>\n","      <th>FL_DATE_MONTH_12</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>...</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","      <td>800000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1328.280338</td>\n","      <td>802.422635</td>\n","      <td>141.343901</td>\n","      <td>12.739946</td>\n","      <td>0.150964</td>\n","      <td>0.143095</td>\n","      <td>0.143526</td>\n","      <td>0.148524</td>\n","      <td>0.149910</td>\n","      <td>0.122398</td>\n","      <td>...</td>\n","      <td>0.084120</td>\n","      <td>0.083326</td>\n","      <td>0.085755</td>\n","      <td>0.086549</td>\n","      <td>0.089074</td>\n","      <td>0.088785</td>\n","      <td>0.081445</td>\n","      <td>0.086284</td>\n","      <td>0.081177</td>\n","      <td>0.083450</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>490.949374</td>\n","      <td>599.559660</td>\n","      <td>73.495999</td>\n","      <td>34.732988</td>\n","      <td>0.358014</td>\n","      <td>0.350170</td>\n","      <td>0.350609</td>\n","      <td>0.355619</td>\n","      <td>0.356983</td>\n","      <td>0.327745</td>\n","      <td>...</td>\n","      <td>0.277568</td>\n","      <td>0.276375</td>\n","      <td>0.280002</td>\n","      <td>0.281173</td>\n","      <td>0.284850</td>\n","      <td>0.284433</td>\n","      <td>0.273517</td>\n","      <td>0.280783</td>\n","      <td>0.273108</td>\n","      <td>0.276561</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>31.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>913.000000</td>\n","      <td>363.000000</td>\n","      <td>88.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1320.000000</td>\n","      <td>634.000000</td>\n","      <td>122.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1735.000000</td>\n","      <td>1035.000000</td>\n","      <td>171.000000</td>\n","      <td>8.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2359.000000</td>\n","      <td>4983.000000</td>\n","      <td>704.000000</td>\n","      <td>300.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 23 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5bbccaa2-66aa-4d93-899e-e8d06333ceb4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5bbccaa2-66aa-4d93-899e-e8d06333ceb4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5bbccaa2-66aa-4d93-899e-e8d06333ceb4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":34}],"source":["df = pd.read_csv('2018-prepared-filtered-sample.csv') \n","df.describe()"]},{"cell_type":"markdown","metadata":{"id":"JYy0AZ425iSd"},"source":["##### Features & Target"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"elapsed":605,"status":"ok","timestamp":1666622444569,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"},"user_tz":-120},"id":"c12tOsw25l_K","outputId":"9178a60a-08b6-4ad5-c365-ecb8e459e2af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["        CRS_DEP_TIME       DISTANCE  CRS_ELAPSED_TIME      ARR_DELAY  \\\n","count  207113.000000  207113.000000     207113.000000  207113.000000   \n","mean     1382.585651     839.169434        145.004794      14.214636   \n","std       475.430466     593.555676         72.603193      11.445973   \n","min       303.000000     151.000000         51.000000       1.000000   \n","25%      1000.000000     399.000000         91.000000       5.000000   \n","50%      1405.000000     674.000000        125.000000      11.000000   \n","75%      1755.000000    1066.000000        174.000000      21.000000   \n","max      2359.000000    4983.000000        681.000000      44.000000   \n","\n","       FL_DATE_WEEKDAY_1  FL_DATE_WEEKDAY_2  FL_DATE_WEEKDAY_3  \\\n","count      207113.000000      207113.000000      207113.000000   \n","mean            0.152839           0.137809           0.141348   \n","std             0.359833           0.344700           0.348381   \n","min             0.000000           0.000000           0.000000   \n","25%             0.000000           0.000000           0.000000   \n","50%             0.000000           0.000000           0.000000   \n","75%             0.000000           0.000000           0.000000   \n","max             1.000000           1.000000           1.000000   \n","\n","       FL_DATE_WEEKDAY_4  FL_DATE_WEEKDAY_5  FL_DATE_WEEKDAY_6  ...  \\\n","count      207113.000000      207113.000000      207113.000000  ...   \n","mean            0.157035           0.161395           0.111929  ...   \n","std             0.363835           0.367896           0.315280  ...   \n","min             0.000000           0.000000           0.000000  ...   \n","25%             0.000000           0.000000           0.000000  ...   \n","50%             0.000000           0.000000           0.000000  ...   \n","75%             0.000000           0.000000           0.000000  ...   \n","max             1.000000           1.000000           1.000000  ...   \n","\n","       FL_DATE_MONTH_3  FL_DATE_MONTH_4  FL_DATE_MONTH_5  FL_DATE_MONTH_6  \\\n","count    207113.000000    207113.000000    207113.000000    207113.000000   \n","mean          0.085205         0.082428         0.085277         0.090347   \n","std           0.279187         0.275017         0.279294         0.286679   \n","min           0.000000         0.000000         0.000000         0.000000   \n","25%           0.000000         0.000000         0.000000         0.000000   \n","50%           0.000000         0.000000         0.000000         0.000000   \n","75%           0.000000         0.000000         0.000000         0.000000   \n","max           1.000000         1.000000         1.000000         1.000000   \n","\n","       FL_DATE_MONTH_7  FL_DATE_MONTH_8  FL_DATE_MONTH_9  FL_DATE_MONTH_10  \\\n","count    207113.000000    207113.000000    207113.000000     207113.000000   \n","mean          0.092635         0.088922         0.071739          0.086933   \n","std           0.289922         0.284632         0.258055          0.281738   \n","min           0.000000         0.000000         0.000000          0.000000   \n","25%           0.000000         0.000000         0.000000          0.000000   \n","50%           0.000000         0.000000         0.000000          0.000000   \n","75%           0.000000         0.000000         0.000000          0.000000   \n","max           1.000000         1.000000         1.000000          1.000000   \n","\n","       FL_DATE_MONTH_11  FL_DATE_MONTH_12  \n","count     207113.000000     207113.000000  \n","mean           0.088647          0.086146  \n","std            0.284235          0.280581  \n","min            0.000000          0.000000  \n","25%            0.000000          0.000000  \n","50%            0.000000          0.000000  \n","75%            0.000000          0.000000  \n","max            1.000000          1.000000  \n","\n","[8 rows x 23 columns]"],"text/html":["\n","  <div id=\"df-96b95c36-1cef-418d-bbe4-d2d5989171eb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CRS_DEP_TIME</th>\n","      <th>DISTANCE</th>\n","      <th>CRS_ELAPSED_TIME</th>\n","      <th>ARR_DELAY</th>\n","      <th>FL_DATE_WEEKDAY_1</th>\n","      <th>FL_DATE_WEEKDAY_2</th>\n","      <th>FL_DATE_WEEKDAY_3</th>\n","      <th>FL_DATE_WEEKDAY_4</th>\n","      <th>FL_DATE_WEEKDAY_5</th>\n","      <th>FL_DATE_WEEKDAY_6</th>\n","      <th>...</th>\n","      <th>FL_DATE_MONTH_3</th>\n","      <th>FL_DATE_MONTH_4</th>\n","      <th>FL_DATE_MONTH_5</th>\n","      <th>FL_DATE_MONTH_6</th>\n","      <th>FL_DATE_MONTH_7</th>\n","      <th>FL_DATE_MONTH_8</th>\n","      <th>FL_DATE_MONTH_9</th>\n","      <th>FL_DATE_MONTH_10</th>\n","      <th>FL_DATE_MONTH_11</th>\n","      <th>FL_DATE_MONTH_12</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>...</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","      <td>207113.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1382.585651</td>\n","      <td>839.169434</td>\n","      <td>145.004794</td>\n","      <td>14.214636</td>\n","      <td>0.152839</td>\n","      <td>0.137809</td>\n","      <td>0.141348</td>\n","      <td>0.157035</td>\n","      <td>0.161395</td>\n","      <td>0.111929</td>\n","      <td>...</td>\n","      <td>0.085205</td>\n","      <td>0.082428</td>\n","      <td>0.085277</td>\n","      <td>0.090347</td>\n","      <td>0.092635</td>\n","      <td>0.088922</td>\n","      <td>0.071739</td>\n","      <td>0.086933</td>\n","      <td>0.088647</td>\n","      <td>0.086146</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>475.430466</td>\n","      <td>593.555676</td>\n","      <td>72.603193</td>\n","      <td>11.445973</td>\n","      <td>0.359833</td>\n","      <td>0.344700</td>\n","      <td>0.348381</td>\n","      <td>0.363835</td>\n","      <td>0.367896</td>\n","      <td>0.315280</td>\n","      <td>...</td>\n","      <td>0.279187</td>\n","      <td>0.275017</td>\n","      <td>0.279294</td>\n","      <td>0.286679</td>\n","      <td>0.289922</td>\n","      <td>0.284632</td>\n","      <td>0.258055</td>\n","      <td>0.281738</td>\n","      <td>0.284235</td>\n","      <td>0.280581</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>303.000000</td>\n","      <td>151.000000</td>\n","      <td>51.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1000.000000</td>\n","      <td>399.000000</td>\n","      <td>91.000000</td>\n","      <td>5.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1405.000000</td>\n","      <td>674.000000</td>\n","      <td>125.000000</td>\n","      <td>11.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1755.000000</td>\n","      <td>1066.000000</td>\n","      <td>174.000000</td>\n","      <td>21.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>2359.000000</td>\n","      <td>4983.000000</td>\n","      <td>681.000000</td>\n","      <td>44.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>...</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 23 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96b95c36-1cef-418d-bbe4-d2d5989171eb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-96b95c36-1cef-418d-bbe4-d2d5989171eb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-96b95c36-1cef-418d-bbe4-d2d5989171eb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":36}],"source":["df.describe()"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"JtnN2H3KkGdA","executionInfo":{"status":"ok","timestamp":1666622444570,"user_tz":-120,"elapsed":7,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}}},"outputs":[],"source":["monthCols, weekdayCols = [], []\n","for a in range(12):\n","  monthCols.append(f\"FL_DATE_MONTH_{a + 1}\")\n","for a in range(7):\n","  weekdayCols.append(f\"FL_DATE_WEEKDAY_{a + 1}\")"]},{"cell_type":"code","source":["# Features & Target\n","COLS_FEATURES = [*monthCols, *weekdayCols ,'CRS_DEP_TIME', 'CRS_ELAPSED_TIME', 'DISTANCE']\n","COLS_TARGET = ['ARR_DELAY']"],"metadata":{"id":"qSv2uA4LU2Kp","executionInfo":{"status":"ok","timestamp":1666622444570,"user_tz":-120,"elapsed":6,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BY_Y4rQ3pb4J"},"source":["Typänderung von int/double zu float32"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"H3KHq0EgpZDr","executionInfo":{"status":"ok","timestamp":1666622444571,"user_tz":-120,"elapsed":7,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}}},"outputs":[],"source":["for item in [*COLS_FEATURES, *COLS_TARGET]:\n","  df[item] = df[item].astype('float32')"]},{"cell_type":"markdown","metadata":{"id":"Q2H9geOWslhS"},"source":["Data normalization"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"xksQneUukHPf","executionInfo":{"status":"ok","timestamp":1666622444571,"user_tz":-120,"elapsed":6,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}}},"outputs":[],"source":["# apply normalization techniques\n","normalize = False\n","if normalize:\n","  for column in df.columns:\n","    df[column] = df[column] / df[column].abs().max()"]},{"cell_type":"markdown","source":["#### Data-Loaders"],"metadata":{"id":"qaNYPFlo2CXT"}},{"cell_type":"markdown","source":["Gruppierung von Features in einem Tensor-Datensatz und die Targets in einem anderen Tensor-Datensatz. Dann wird ein vollständiger Datensatz mit beiden erstellt"],"metadata":{"id":"3zoK1iZBMX_7"}},{"cell_type":"code","execution_count":41,"metadata":{"id":"q1l8ahvlzBGQ","executionInfo":{"status":"ok","timestamp":1666622444877,"user_tz":-120,"elapsed":10,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}}},"outputs":[],"source":["torch_tensor_features = torch.tensor(df[COLS_FEATURES].values)\n","torch_tensor_target = torch.tensor(df[COLS_TARGET].values)\n","\n","torch_dataset = torch.utils.data.TensorDataset(torch_tensor_features, torch_tensor_target) "]},{"cell_type":"markdown","source":["Wir teilen die Daten auf, 80% für das Training und 20% für die Tests"],"metadata":{"id":"6n_hc_UsMHjF"}},{"cell_type":"code","execution_count":42,"metadata":{"id":"iZJfGa2qDeEY","executionInfo":{"status":"ok","timestamp":1666622444878,"user_tz":-120,"elapsed":11,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}}},"outputs":[],"source":["# Train/Split\n","train_set, test_set = torch.utils.data.random_split(torch_dataset, [ int(len(torch_dataset)*0.8), (len(torch_dataset) - int(len(torch_dataset)*0.8)) ] )"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"N-ID1VWQBXfu","executionInfo":{"status":"ok","timestamp":1666622444878,"user_tz":-120,"elapsed":11,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}}},"outputs":[],"source":["# We pass the \"Dataset\" as an argument to \"DataLoader\".\n","# in the dataloader iterable will return a batch of 64 features and labels.\n","\n","batch_size = 5000\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n","\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1666622444878,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"},"user_tz":-120},"id":"OS0M5wenwcEB","outputId":"3c716c10-cbc8-4353-9dbc-8b61d25eb34a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n"]}],"source":["# Get cpu or gpu device for training.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","metadata":{"id":"4MlgsvqFwRny"},"source":["#### Model"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"jpvwcf-dwS0X","executionInfo":{"status":"ok","timestamp":1666622444879,"user_tz":-120,"elapsed":11,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}}},"outputs":[],"source":["# Define model\n","class NeuralNetwork(nn.Module):\n","    def __init__(self, layers = [25, 25]):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        sequentials = []\n","        for index, l in enumerate(layers): # Generate Sequntial-Layers based on input\n","          if index == 0:\n","            sequentials.append(nn.Linear(len(COLS_FEATURES), layers[index]))\n","            sequentials.append(nn.ReLU())\n","          if index != 0 & index != len(layers) - 1:\n","            sequentials.append(nn.Linear(layers[index - 1], layers[index]))\n","            sequentials.append(nn.ReLU())\n","          if index == len(layers) - 1:\n","            sequentials.append(nn.Linear(layers[index - 1], 1))\n","            #sequentials(torch.nn.Softmax())\n","        self.linear_relu_stack = nn.Sequential(*sequentials)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits"]},{"cell_type":"markdown","metadata":{"id":"vJMeMfB6rOYR"},"source":["##### Model - Train & Test "]},{"cell_type":"code","execution_count":46,"metadata":{"id":"hce701azlfTd","executionInfo":{"status":"ok","timestamp":1666622444879,"user_tz":-120,"elapsed":10,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}}},"outputs":[],"source":["# In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and\n","# backpropagates the prediction error to adjust the model's parameters.\n","def train(dataloader, model, loss_fn, optimizer):\n","  size = len(dataloader.dataset)\n","  for batch, (X, y) in enumerate(dataloader):\n","      X, y = X.to(device), y.to(device)\n","      # Compute prediction error\n","      pred = model(X)\n","      loss = loss_fn(pred, y)\n","\n","      # Backpropagation\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","# We also check the model's performance against the test dataset to ensure it is learning.\n","def test(dataloader, model, loss_fn):\n","  size = len(dataloader.dataset)\n","  num_batches = len(dataloader)\n","  model.eval()\n","  test_loss, correct = 0, 0\n","  preds, ys = [], []\n","  with torch.no_grad():\n","    for X, y in dataloader:\n","      X, y = X.to(device), y.to(device)\n","      pred = model(X)\n","      test_loss += loss_fn(pred, y).item()\n","      preds.extend(pred)\n","      ys.extend(y)\n","\n","      return preds, ys, test_loss\n","\n","def accuracy(preds, ys, pct):\n","  n_correct, n_wrong = 0, 0\n","  for index, pred in enumerate(preds):\n","    abs_delta = np.abs(pred - ys[index])\n","    max_allow = np.abs((1 + pct) * ys[index])\n","    if abs_delta < max_allow:\n","      n_correct +=1\n","    else:\n","      n_wrong += 1\n","\n","  return n_correct / (n_correct + n_wrong)\n","\n","# To train a model, we need a `loss function for regression model\n","loss_fn = nn.MSELoss()"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51348,"status":"ok","timestamp":1666622496217,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"},"user_tz":-120},"id":"rouTXHWG6Juz","outputId":"92132f7e-e844-49fb-bba6-9432e0a558fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1\n","-------------------------------\n","Epoch 2\n","-------------------------------\n","Epoch 3\n","-------------------------------\n","Epoch 4\n","-------------------------------\n","Epoch 5\n","-------------------------------\n","Epoch 6\n","-------------------------------\n","Epoch 7\n","-------------------------------\n","Epoch 8\n","-------------------------------\n","Epoch 9\n","-------------------------------\n","Epoch 10\n","-------------------------------\n","Accuracy = 73.89%\n"]}],"source":["def trainModel(layers=[100, 100], epochs= 10):\n","  model = NeuralNetwork(layers=[100, 100]).to(device)\n","  optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.0001)\n","\n","  losses, accuracies, y, pred = [], [], [], []\n","\n","  for t in range(epochs):\n","      print(f\"Epoch {t+1}\\n-------------------------------\")\n","      train(dataloader=train_loader, model=model, loss_fn=loss_fn, optimizer=optimizer)\n","      testRes = test(test_loader, model, loss_fn)\n","      losses.append(testRes[2])\n","      # accuracy\n","      pred = list(map(lambda a: a.item(), testRes[0]))\n","      y = list(map(lambda a: a.item(), testRes[1]))\n","      accuracies.append(accuracy(pred, y, 0.5))\n","\n","  print(f\"Accuracy = {np.array(accuracies).sum()/len(accuracies) * 100}%\")\n","\n","  return model, losses, accuracies, y, pred\n","\n","\n","model, losses, accuracies, y, pred  = trainModel()"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":940,"status":"ok","timestamp":1666622732431,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"},"user_tz":-120},"id":"bDmhp32eA9fY","colab":{"base_uri":"https://localhost:8080/","height":442},"outputId":"10be25f0-c0f2-4f8d-d36d-9c7e8383299d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x504 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["def plotLossAndAccuracy(losses, accuracies):  \n","  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 7))\n","  ax1.plot(losses, '-o', color='purple', label='Loss')\n","  ax1.set_xlabel(\"Epochs\")\n","  ax1.legend()\n","\n","  ax2.plot(accuracies, '-o', label='Accuracy')\n","  ax2.set_xlabel(\"Epochs\")\n","  ax2.legend()\n","  plt.show()\n","\n","plotLossAndAccuracy(losses, accuracies)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qTQVSRpe_ETL"},"outputs":[],"source":["def showLossPlot(y_test, y_pred):\n","  fig, ax = plt.subplots(1, 1, figsize=(9, 7) )\n","  sns.set_theme(style=\"darkgrid\")\n","  sns.scatterplot(y_test, y_pred, ax=ax)\n","  ax.set_title('Loss')\n","  ax.set_xlabel('Verspätung')\n","  ax.set_ylabel('Vorausgesagte Verspätung')\n","  z = np.polyfit(y_test, y_pred, 1)\n","  p = np.poly1d(z)\n","  ax.plot(y_test, p(y_test), color='red')\n","\n","#showLossPlot(y, pred)"]},{"cell_type":"markdown","metadata":{"id":"Crnlrbm89t-E"},"source":["#### Cross-Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sl-Aux079tbK","executionInfo":{"status":"ok","timestamp":1666551235175,"user_tz":-120,"elapsed":403674,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc1bdf89-f64b-47ce-be4a-62ee2b7b06c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------\n","FOLD 0\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=22, out_features=100, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=100, out_features=1, bias=True)\n","Starting epoch 1\n","Starting epoch 2\n","Starting epoch 3\n","Starting epoch 4\n","Starting epoch 5\n","Starting testing\n","TEST tensor([[18.1037]]) tensor([0]) tensor([[6.]])\n","Accuracy for fold 0: 62 %\n","--------------------------------\n","FOLD 1\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=22, out_features=100, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=100, out_features=1, bias=True)\n","Starting epoch 1\n","Starting epoch 2\n","Starting epoch 3\n","Starting epoch 4\n","Starting epoch 5\n","Starting testing\n","TEST tensor([[15.4130]]) tensor([0]) tensor([[7.]])\n","Accuracy for fold 1: 64 %\n","--------------------------------\n","FOLD 2\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=22, out_features=100, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=100, out_features=1, bias=True)\n","Starting epoch 1\n","Starting epoch 2\n","Starting epoch 3\n","Starting epoch 4\n","Starting epoch 5\n","Starting testing\n","TEST tensor([[10.9441]]) tensor([0]) tensor([[17.]])\n","Accuracy for fold 2: 61 %\n","--------------------------------\n","FOLD 3\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=22, out_features=100, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=100, out_features=1, bias=True)\n","Starting epoch 1\n","Starting epoch 2\n","Starting epoch 3\n","Starting epoch 4\n","Starting epoch 5\n","Starting testing\n","TEST tensor([[14.4606]]) tensor([0]) tensor([[7.]])\n","Accuracy for fold 3: 63 %\n","--------------------------------\n","FOLD 4\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=22, out_features=100, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=100, out_features=100, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=100, out_features=1, bias=True)\n","Starting epoch 1\n","Starting epoch 2\n","Starting epoch 3\n","Starting epoch 4\n","Starting epoch 5\n","Starting testing\n","TEST tensor([[19.1898]]) tensor([0]) tensor([[36.]])\n","Accuracy for fold 4: 61 %\n","--------------------------------\n","K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n","--------------------------------\n","Fold 0: 62.66325471356493 %\n","Fold 1: 64.2227747869541 %\n","Fold 2: 61.135118171064384 %\n","Fold 3: 63.852542127371926 %\n","Fold 4: 61.807735020037654 %\n","Average: 62.73628496379861 %\n"]}],"source":["def reset_weights(m):\n","  # resetting model weights to avoid weight leakage.\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","\n","# Define the K-fold Cross Validator\n","k_folds = 5\n","num_epochs = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","\n","# For fold results\n","results = {}\n","\n","# Start print\n","print('--------------------------------')\n","\n","# K-fold Cross Validation model evaluation\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(torch_dataset)):\n","  # Print\n","  print(f'FOLD {fold}')\n","  print('--------------------------------')\n","\n","  # Sample elements randomly from a given list of ids, no replacement.\n","  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","  test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","\n","  # Define data loaders for training and testing data in this fold\n","  trainloader = torch.utils.data.DataLoader(torch_dataset, batch_size=1, sampler=train_subsampler)\n","  testloader = torch.utils.data.DataLoader(torch_dataset, batch_size=1, sampler=test_subsampler)\n","  \n","  # model\n","  network = NeuralNetwork(layers=[100, 100])\n","  network.apply(reset_weights)\n","\n","  # Initialize optimizer\n","  optimizer = torch.optim.Adam(network.parameters(), lr=1e-4)\n","    \n","  # Run the training loop for defined number of epochs\n","  for epoch in range(0, num_epochs):\n","    print(f'Starting epoch {epoch+1}')\n","\n","    current_loss = 0.0\n","\n","    # Iterate over the DataLoader for training data\n","    for i, data in enumerate(trainloader, 0):\n","      # Get inputs\n","      inputs, targets = data\n","        \n","      # Zero the gradients\n","      optimizer.zero_grad()\n","        \n","      # Perform forward pass\n","      outputs = network(inputs)\n","\n","      # Compute loss\n","      loss = loss_fn(outputs, targets)\n","        \n","      # Perform backward pass\n","      loss.backward()\n","        \n","      optimizer.step()\n","\n","  print('Starting testing')\n","\n","  # Evaluationfor this fold\n","  correct, total = 0, 0\n","  with torch.no_grad():\n","\n","    # Iterate over the test data and generate predictions\n","    for i, data in enumerate(testloader, 0):\n","      inputs, targets = data\n","\n","      outputs = network(inputs)\n","\n","      # Set total and correct\n","      _, predicted = torch.max(outputs.data, 1)\n","      total += targets.size(0)\n","      #targetList = torch.tensor(list(map(lambda a: a[0].item(), targets)))\n","      if i == 0:\n","        print('TEST', outputs.data, predicted, targets)\n","\n","      correct += np.isclose(outputs.data, targets, atol=10).sum().item() if len(outputs.data) == len(targets) else 0\n","    \n","    # Print accuracy\n","    print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","    print('--------------------------------')\n","    results[fold] = 100.0 * (correct / total)\n","\n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')"]},{"cell_type":"markdown","metadata":{"id":"oEIrMZot-Uhf"},"source":["#### Parameter-Tuning"]},{"cell_type":"code","source":["def load_data():\n","    return train_set, test_set"],"metadata":{"id":"55vjLE7uv6D6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model"],"metadata":{"id":"zedMzd_Vv-Ed"}},{"cell_type":"code","source":["best_trial = None\n","# Define model\n","class Net(nn.Module):\n","    def __init__(self, l1=25, l2=25):\n","        super(Net, self).__init__()\n","        self.flatten = nn.Flatten()\n","        sequentials = []\n","        sequentials.append(nn.Linear(len(COLS_FEATURES), l1))\n","        sequentials.append(nn.ReLU())\n","\n","        sequentials.append(nn.Linear(l1, l2))\n","        sequentials.append(nn.ReLU())\n","\n","        sequentials.append(nn.Linear(l2, 1))\n","        self.linear_relu_stack = nn.Sequential(*sequentials)\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits"],"metadata":{"id":"MjvNfovnv-1n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train"],"metadata":{"id":"68qOqs_HwOdY"}},{"cell_type":"code","source":["def train_hyper(config, checkpoint_dir=None, data_dir=None, iterations=1):\n","    net = Net(config[\"l1\"], config[\"l2\"])\n","\n","    criterion = nn.MSELoss()\n","    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n","\n","    if checkpoint_dir:\n","        model_state, optimizer_state = torch.load(os.path.join(checkpoint_dir, \"checkpoint\"))\n","        net.load_state_dict(model_state)\n","        optimizer.load_state_dict(optimizer_state)\n","\n","    trainset, testset = load_data()\n","\n","    test_abs = int(len(trainset) * 0.8)\n","    train_subset, val_subset = random_split(trainset, [test_abs, len(trainset) - test_abs])\n","\n","    trainloader = torch.utils.data.DataLoader(\n","        train_subset,\n","        batch_size=int(config[\"batch_size\"]),\n","        shuffle=True,\n","        num_workers=8)\n","    valloader = torch.utils.data.DataLoader(\n","        val_subset,\n","        batch_size=int(config[\"batch_size\"]),\n","        shuffle=True,\n","        num_workers=8)\n","\n","    for epoch in range(iterations):  # loop over the dataset multiple times\n","        running_loss = 0.0\n","        epoch_steps = 0\n","        for i, data in enumerate(trainloader, 0):\n","            # get the inputs; data is a list of [inputs, labels]\n","            inputs, labels = data\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = net(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print statistics\n","            running_loss += loss.item()\n","            epoch_steps += 1\n","            if i % 2000 == 1999:  # print every 2000-th mini-batches\n","                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n","                                                running_loss / epoch_steps))\n","                running_loss = 0.0\n","\n","        # Validation loss\n","        val_loss = 0.0\n","        val_steps = 0\n","        total = 0\n","        correct = 0\n","        for i, data in enumerate(valloader, 0):\n","            with torch.no_grad():\n","                inputs, labels = data\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                outputs = net(inputs)\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.cpu().numpy()\n","                val_steps += 1\n","\n","        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n","            path = os.path.join(checkpoint_dir, \"checkpoint\")\n","            torch.save((net.state_dict(), optimizer.state_dict()), path)\n","\n","        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n","    print(\"Finished Training\")"],"metadata":{"id":"WlpyHYQQwPZh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test"],"metadata":{"id":"lyaUTKlrwScG"}},{"cell_type":"code","source":["# TEST FUNCTION\n","def test_hyper_accuracy(net, device=\"cpu\"):\n","    trainset, testset = load_data()\n","\n","    testloader = torch.utils.data.DataLoader(\n","        testset, batch_size=4, shuffle=False, num_workers=2)\n","\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = net(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    return correct / total"],"metadata":{"id":"2pQfmU-HwXTQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Konfiguration & Start-Funktion"],"metadata":{"id":"QNZwox3GwjI2"}},{"cell_type":"code","source":["# MAIN START FUNCTION\n","def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2, iterations=10):\n","   \n","    data_dir = os.path.abspath(\"./data\")\n","    load_data()\n","    config = {\n","        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n","        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n","        \"lr\": tune.loguniform(1e-4, 1e-1),\n","        \"batch_size\": tune.choice([2, 4, 8, 16])\n","    }\n","    scheduler = ASHAScheduler(\n","        metric=\"loss\",\n","        mode=\"min\",\n","        max_t=max_num_epochs,\n","        grace_period=1,\n","        reduction_factor=2)\n","    \n","    reporter = CLIReporter(\n","        parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n","        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n","    \n","    result = tune.run(\n","        partial(train_hyper, data_dir=data_dir, iterations=iterations), \n","        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial}, \n","        config=config,\n","        num_samples=num_samples,\n","        scheduler=scheduler,\n","        progress_reporter=reporter)\n","\n","    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n","    print(\"Best trial config: {}\".format(best_trial.config))\n","    print(\"Best trial final validation loss: {}\".format(\n","        best_trial.last_result[\"loss\"]))\n","    #print(\"Best trial final validation accuracy: {}\".format(\n","    #    best_trial.last_result[\"accuracy\"]))\n","\n","\n","main(num_samples=1, max_num_epochs=1, gpus_per_trial=0, iterations=1) # max_num_epochs=10"],"metadata":{"id":"NGCmXQ0A0a7P","executionInfo":{"status":"ok","timestamp":1666553131455,"user_tz":-120,"elapsed":33398,"user":{"displayName":"Herbi Shtini","userId":"03158017251313112277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"593363bb-9417-4199-c1d6-337d16c2c7eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-10-23 19:24:57,755\tWARNING callback.py:109 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n","2022-10-23 19:24:58,519\tWARNING worker.py:1829 -- Warning: The actor ImplicitFunc is very large (19 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n","2022-10-23 19:24:58,932\tWARNING util.py:244 -- The `start_trial` operation took 0.764 s, which may be a performance bottleneck.\n"]},{"output_type":"stream","name":"stdout","text":["== Status ==\n","Current time: 2022-10-23 19:24:58 (running for 00:00:01.18)\n","Memory usage on this node: 2.0/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_hyper_2022-10-23_19-24-57\n","Number of trials: 1/1 (1 RUNNING)\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","| Trial name              | status   | loc             |   l1 |   l2 |        lr |   batch_size |\n","|-------------------------+----------+-----------------+------+------+-----------+--------------|\n","| train_hyper_616a2_00000 | RUNNING  | 172.28.0.2:1573 |   16 |  256 | 0.0212979 |           16 |\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(func pid=1573)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","\u001b[2m\u001b[36m(func pid=1573)\u001b[0m   cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["== Status ==\n","Current time: 2022-10-23 19:25:07 (running for 00:00:09.71)\n","Memory usage on this node: 2.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_hyper_2022-10-23_19-24-57\n","Number of trials: 1/1 (1 RUNNING)\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","| Trial name              | status   | loc             |   l1 |   l2 |        lr |   batch_size |\n","|-------------------------+----------+-----------------+------+------+-----------+--------------|\n","| train_hyper_616a2_00000 | RUNNING  | 172.28.0.2:1573 |   16 |  256 | 0.0212979 |           16 |\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=1573)\u001b[0m [1,  2000] loss: nan\n","== Status ==\n","Current time: 2022-10-23 19:25:12 (running for 00:00:14.73)\n","Memory usage on this node: 2.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_hyper_2022-10-23_19-24-57\n","Number of trials: 1/1 (1 RUNNING)\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","| Trial name              | status   | loc             |   l1 |   l2 |        lr |   batch_size |\n","|-------------------------+----------+-----------------+------+------+-----------+--------------|\n","| train_hyper_616a2_00000 | RUNNING  | 172.28.0.2:1573 |   16 |  256 | 0.0212979 |           16 |\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=1573)\u001b[0m [1,  4000] loss: nan\n","== Status ==\n","Current time: 2022-10-23 19:25:17 (running for 00:00:19.74)\n","Memory usage on this node: 2.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_hyper_2022-10-23_19-24-57\n","Number of trials: 1/1 (1 RUNNING)\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","| Trial name              | status   | loc             |   l1 |   l2 |        lr |   batch_size |\n","|-------------------------+----------+-----------------+------+------+-----------+--------------|\n","| train_hyper_616a2_00000 | RUNNING  | 172.28.0.2:1573 |   16 |  256 | 0.0212979 |           16 |\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=1573)\u001b[0m [1,  6000] loss: nan\n","== Status ==\n","Current time: 2022-10-23 19:25:22 (running for 00:00:24.75)\n","Memory usage on this node: 2.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_hyper_2022-10-23_19-24-57\n","Number of trials: 1/1 (1 RUNNING)\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","| Trial name              | status   | loc             |   l1 |   l2 |        lr |   batch_size |\n","|-------------------------+----------+-----------------+------+------+-----------+--------------|\n","| train_hyper_616a2_00000 | RUNNING  | 172.28.0.2:1573 |   16 |  256 | 0.0212979 |           16 |\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","\n","\n","\u001b[2m\u001b[36m(func pid=1573)\u001b[0m [1,  8000] loss: nan\n","== Status ==\n","Current time: 2022-10-23 19:25:27 (running for 00:00:29.75)\n","Memory usage on this node: 2.3/12.7 GiB\n","Using AsyncHyperBand: num_stopped=0\n","Bracket: Iter 1.000: None\n","Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_hyper_2022-10-23_19-24-57\n","Number of trials: 1/1 (1 RUNNING)\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","| Trial name              | status   | loc             |   l1 |   l2 |        lr |   batch_size |\n","|-------------------------+----------+-----------------+------+------+-----------+--------------|\n","| train_hyper_616a2_00000 | RUNNING  | 172.28.0.2:1573 |   16 |  256 | 0.0212979 |           16 |\n","+-------------------------+----------+-----------------+------+------+-----------+--------------+\n","\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/lib/nanfunctions.py:1376: RuntimeWarning: All-NaN slice encountered\n","  overwrite_input=overwrite_input, interpolation=interpolation\n","2022-10-23 19:25:30,889\tINFO tune.py:759 -- Total run time: 33.59 seconds (33.00 seconds for the tuning loop).\n"]},{"output_type":"stream","name":"stdout","text":["Result for train_hyper_616a2_00000:\n","  accuracy: 0.0\n","  date: 2022-10-23_19-25-30\n","  done: true\n","  experiment_id: c04aa116cf0745e6b30959c95a02607a\n","  hostname: bbe44acddf64\n","  iterations_since_restore: 1\n","  loss: .nan\n","  node_ip: 172.28.0.2\n","  pid: 1573\n","  should_checkpoint: true\n","  time_since_restore: 28.280117988586426\n","  time_this_iter_s: 28.280117988586426\n","  time_total_s: 28.280117988586426\n","  timestamp: 1666553130\n","  timesteps_since_restore: 0\n","  training_iteration: 1\n","  trial_id: 616a2_00000\n","  warmup_time: 0.0038690567016601562\n","  \n","== Status ==\n","Current time: 2022-10-23 19:25:30 (running for 00:00:33.02)\n","Memory usage on this node: 2.2/12.7 GiB\n","Using AsyncHyperBand: num_stopped=1\n","Bracket: Iter 1.000: nan\n","Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.37 GiB heap, 0.0/3.69 GiB objects\n","Result logdir: /root/ray_results/train_hyper_2022-10-23_19-24-57\n","Number of trials: 1/1 (1 TERMINATED)\n","+-------------------------+------------+-----------------+------+------+-----------+--------------+--------+------------+----------------------+\n","| Trial name              | status     | loc             |   l1 |   l2 |        lr |   batch_size |   loss |   accuracy |   training_iteration |\n","|-------------------------+------------+-----------------+------+------+-----------+--------------+--------+------------+----------------------|\n","| train_hyper_616a2_00000 | TERMINATED | 172.28.0.2:1573 |   16 |  256 | 0.0212979 |           16 |    nan |          0 |                    1 |\n","+-------------------------+------------+-----------------+------+------+-----------+--------------+--------+------------+----------------------+\n","\n","\n","Best trial config: {'l1': 16, 'l2': 256, 'lr': 0.021297912913995597, 'batch_size': 16}\n","Best trial final validation loss: nan\n"]}]},{"cell_type":"code","source":["model, losses, accuracies, y, pred = trainModel(layers=[16, 254])\n","plotLossAndAccuracy(losses, accuracies)"],"metadata":{"id":"70nSb44_PfGC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1JgJLOGMq32m"},"source":["#### Model-Speichern"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tYvAfbQsLIMZ"},"outputs":[],"source":["torch.save(model.state_dict(), \"model.pth\")"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}